

# === README.md ===

# sensible-fitting
An overarching framework wrapping fitting libraries/functions providing a common API for different backends. It (opinionatedly) focuses on fit functions related to AMO physics. It helps to guess seed parameters and provides a unified and sensible API that is quick to use. This library is currently just used in our labs, but I indend to make it 'nice' for public good at some point.

This project was born out of the desire to replace the (`oitg`)[https://github.com/OxfordIonTrapGroup/oitg]
dependency of (`ndscan`)[https://github.com/OxfordIonTrapGroup/ndscan]. This dependency primarily comes through the plotting functions.


# === dump_code.py ===

#!/usr/bin/env python3
from pathlib import Path

ROOT = Path(".").resolve()
OUT = Path("repo_dump.txt")

INCLUDE = {".py", ".toml", ".md"}
EXCLUDE_DIRS = {".git", ".venv", "__pycache__", ".pytest_cache", ".mypy_cache", "dist", "build"}
EXCLUDE_FILES_SUFFIX = {".pyc"}

def should_skip(path: Path) -> bool:
    if any(part in EXCLUDE_DIRS for part in path.parts):
        return True
    if path.suffix in EXCLUDE_FILES_SUFFIX:
        return True
    return False

files = []
for p in ROOT.rglob("*"):
    if not p.is_file():
        continue
    if should_skip(p):
        continue
    if p.suffix not in INCLUDE:
        continue
    files.append(p)

files.sort()

with OUT.open("w", encoding="utf-8") as f:
    for p in files:
        rel = p.relative_to(ROOT)
        f.write(f"\n\n# === {rel} ===\n\n")
        try:
            f.write(p.read_text(encoding="utf-8"))
        except UnicodeDecodeError:
            f.write("<binary or non-utf8 file skipped>\n")

print(f"Wrote {OUT} with {len(files)} files.")


# === examples/01_line.py ===

import numpy as np
import matplotlib.pyplot as plt
from sensible_fitting import Model

def line(x, m, b):
    return m * x + b

model = Model.from_function(line, name="straight line")

rng = np.random.default_rng(0)
x = np.linspace(0, 10, 50)
y_true = line(x, 2.0, -1.0)
sigma = 0.6
y = y_true + rng.normal(0, sigma, size=x.size)

run = model.fit(x=x, y=(y, sigma), backend="scipy.curve_fit", return_run=True).squeeze()
res = run.results

print(res.params["m"].value, "±", res.params["m"].error)
print(res.params["b"].value, "±", res.params["b"].error)
print(res.summary(digits=4))

fig, ax = plt.subplots()
ax.errorbar(x, y, yerr=sigma, fmt="o", ms=4, capsize=2, label="data")

xg = np.linspace(x.min(), x.max(), 400)
ax.plot(xg, run.model.eval(xg, params=res.params), label="fit")

band = run.band(xg, nsamples=400, level=2)
ax.fill_between(xg, band.low, band.high, alpha=0.2, label="~2σ band")

ax.legend()
ax.set_xlabel("x")
ax.set_ylabel("y")
plt.show()


# === examples/02_batch_common_x.py ===

import numpy as np
import matplotlib.pyplot as plt
from sensible_fitting import models

model = (
    models.sinusoid(name="wave")
    .fix(offset=0.0, phase=np.pi/3)
    .bound(amplitude=(0.2, 5.0), frequency=(1.0, 6.0))
    .guess(frequency=2.8)
    .autoguess("amplitude")
)

rng = np.random.default_rng(2)
N_SYSTEMS, N = 4, 250
x = np.linspace(0, 1, N)

A0, F0 = 2.0, 3.0
A = A0*(1 + 0.05*rng.normal(size=N_SYSTEMS))
F = F0*(1 + 0.02*rng.normal(size=N_SYSTEMS))

sigma = 0.2
y_clean = np.stack([model.eval(x, amplitude=A[i], frequency=F[i]) for i in range(N_SYSTEMS)])
y = y_clean + rng.normal(0, sigma, size=y_clean.shape)

run = model.fit(x=x, y=(y, sigma), backend="scipy.curve_fit", return_run=True)
res = run.results
print(res.summary(digits=4))

fig, axs = plt.subplots(2, 2, figsize=(10, 7), sharex=True, sharey=True)
axs = axs.ravel()
xg = np.linspace(x.min(), x.max(), 500)

for i, ax in enumerate(axs):
    ax.errorbar(x, y[i], yerr=sigma, fmt=".", ms=3, label=f"data {i}")
    yi = run.model.eval(xg, params=res[i].params)
    ax.plot(xg, yi, label="fit")
    band = run[i].band(xg, nsamples=300, level=2)
    ax.fill_between(xg, band.low, band.high, alpha=0.2)
    ax.set_title(f"system {i}")
    ax.legend()

plt.show()


# === examples/03_batch_ragged_x.py ===

import numpy as np
from sensible_fitting import models

model = models.straight_line()

rng = np.random.default_rng(123)
xs = []
ys = []

for i in range(3):
    n = 30 + 10 * i
    x = np.sort(rng.uniform(-2, 2, size=n))
    sigma = 0.1 + 0.05 * rng.random(size=n)
    y = 0.5 * x - 0.1 + rng.normal(0, sigma)
    xs.append(x)
    ys.append((y, sigma))

run = model.fit(x=xs, y=ys, backend="scipy.curve_fit", return_run=True)
print(run.results.summary(digits=4))


# === examples/04_backend_swap.py ===

import numpy as np
import matplotlib.pyplot as plt
from sensible_fitting import Model

def line(x, m, b):
    return m*x + b

# bounds (useful for future Bayesian backends)
model = Model.from_function(line).bound(m=(-10,10), b=(-10,10))

rng = np.random.default_rng(5)
x = np.linspace(0, 4, 50)
sigma = 0.3
y = line(x, 1.7, -0.4) + rng.normal(0, sigma, size=x.size)

run_cf = model.fit(x=x, y=(y, sigma), backend="scipy.curve_fit", return_run=True).squeeze()

fig, ax = plt.subplots()
ax.errorbar(x, y, yerr=sigma, fmt=".", label="data")

xg = np.linspace(x.min(), x.max(), 400)
ax.plot(xg, run_cf.model.eval(xg, params=run_cf.results.params), label="curve_fit")

band_cf = run_cf.band(xg, level=2, method="covariance")
ax.fill_between(xg, band_cf.low, band_cf.high, alpha=0.2, label="curve_fit ~2σ")

ax.legend()
plt.show()


# === examples/05_derived_params.py ===

import numpy as np
from sensible_fitting import Model

def gaussian(x, amp, mu, sigma):
    return amp * np.exp(-0.5 * ((x - mu)/sigma)**2)

model = (
    Model.from_function(gaussian)
      .bound(amp=(0, None), sigma=(1e-6, None))
      .derive("fwhm", lambda p: 2.354820045 * p["sigma"], doc="Full-width at half maximum")
)

rng = np.random.default_rng(0)
x = np.linspace(-3, 3, 200)
sigma_y = 0.05
y = model.eval(x, amp=1.0, mu=0.2, sigma=0.7) + rng.normal(0, sigma_y, size=x.size)

run = model.fit(x=x, y=(y, sigma_y), backend="scipy.curve_fit", return_run=True).squeeze()
res = run.results

print("sigma:", res.params["sigma"].value)
print("fwhm :", res.params["fwhm"].value, "(derived:", res.params["fwhm"].derived, ")")


# === examples/06_fit_on_off.py ===

import numpy as np
import matplotlib.pyplot as plt
from sensible_fitting import models

fit_data = True  # True => fit. False => plot seed only.

model = (
    models.sinusoid(name="wave")
    .fix(offset=0.0, phase=np.pi / 3)
    .bound(amplitude=(0.2, 5.0), frequency=(1.0, 6.0))
    .guess(frequency=2.8)
    .autoguess("amplitude")
)

rng = np.random.default_rng(2)
N = 25
x = np.linspace(0, 1, N)

sigma = 0.6
y = model.eval(x, amplitude=2.0, frequency=3.0) + rng.normal(0, sigma, size=x.size)

# One code path: always produces a Run
run = model.fit(
    x=x,
    y=(y, sigma),
    backend="scipy.curve_fit",
    return_run=True,
    skip=not fit_data,           # <--- THE KEY
).squeeze()

res = run.results

# Plot
fig, ax = plt.subplots()
ax.errorbar(x, y, yerr=sigma, fmt=".", ms=3, label="data")

xg = np.linspace(x.min(), x.max(), 500)

style = "-" if fit_data else "--"
label = "fit" if fit_data else "seed fit"
ax.plot(xg, run.model.eval(xg, params=res.params), linestyle=style, label=label)

# Band only if covariance exists (fit mode)
if res.cov is not None:
    band = run.band(xg, level=2, nsamples=400)
    ax.fill_between(xg, band.low, band.high, alpha=0.2, label="~2σ band")

ax.legend()
ax.set_xlabel("x")
ax.set_ylabel("y")
plt.show()

# Print params either way
print(res.summary(digits=5))


# === pyproject.toml ===

[project]
name = "sensible-fitting"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
authors = [
    { name = "tomhepz", email = "9285131+tomhepz@users.noreply.github.com" }
]
requires-python = ">=3.14"
dependencies = [
    "lmfit>=1.3.4",
    "numpy>=2.3.5",
    "scipy>=1.16.3",
    "ultranest>=4.4.0",
    "uncertainties>=3.2.3",
]

[build-system]
requires = ["uv_build>=0.9.11,<0.10.0"]
build-backend = "uv_build"

[dependency-groups]
dev = [
    "matplotlib>=3.10.7",
    "pyqt6>=6.10.1",
]


# === src/sensible_fitting/__init__.py ===

"""sensible_fitting public API."""
from .model import Model
from .run import Run, Results, Band
from . import models

__all__ = ["Model", "Run", "Results", "Band", "models"]


# === src/sensible_fitting/backends/__init__.py ===

"""Backend implementations."""


# === src/sensible_fitting/backends/scipy_curve_fit.py ===

from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Callable, Dict, Optional, Tuple

import numpy as np
from scipy.optimize import curve_fit


@dataclass(frozen=True)
class CurveFitResult:
    popt: np.ndarray
    pcov: Optional[np.ndarray]
    success: bool
    message: str = ""


def fit_curve_fit(
    f_wrapped: Callable[..., Any],
    x: Any,
    y: np.ndarray,
    *,
    sigma: Optional[np.ndarray],
    p0: np.ndarray,
    bounds: Tuple[np.ndarray, np.ndarray],
    maxfev: Optional[int] = None,
) -> CurveFitResult:
    kwargs: Dict[str, Any] = {}
    if maxfev is not None:
        kwargs["maxfev"] = int(maxfev)

    try:
        popt, pcov = curve_fit(
            f_wrapped,
            x,
            y,
            p0=p0,
            sigma=sigma,
            # v1: provided errors are absolute measurement errors
            absolute_sigma=(sigma is not None),
            bounds=bounds,
            **kwargs,
        )
        return CurveFitResult(popt=np.asarray(popt, float), pcov=pcov, success=True, message="ok")
    except Exception as e:
        return CurveFitResult(popt=np.asarray(p0, float), pcov=None, success=False, message=str(e))


# === src/sensible_fitting/model.py ===

from __future__ import annotations

from dataclasses import dataclass, replace
from typing import Any, Callable, Dict, Iterable, List, Literal, Mapping, Optional, Sequence, Tuple, Union

import numpy as np

from .backends.scipy_curve_fit import fit_curve_fit
from .params import DerivedSpec, GuessState, ParameterSpec, ParamView, ParamsView
from .run import Results, Run
from .util import flatten_batch, infer_param_names, is_ragged_batch, prod, unflatten_batch


Guesser = Callable[[Any, Any, GuessState], None]


@dataclass
class Model:
    """A model wraps a callable and parameter metadata."""
    name: str
    func: Callable[..., Any]
    param_names: Tuple[str, ...]
    params: Tuple[ParameterSpec, ...]
    guessers: Tuple[Guesser, ...] = ()
    derived: Tuple[DerivedSpec, ...] = ()
    autoguess_names: Tuple[str, ...] = ()
    meta: Dict[str, Any] = None

    # ---- constructor ----
    @staticmethod
    def from_function(func: Callable[..., Any], *, name: Optional[str] = None) -> "Model":
        names = infer_param_names(func)
        specs = tuple(ParameterSpec(name=n) for n in names)
        return Model(name=name or getattr(func, "__name__", "model"), func=func, param_names=names, params=specs)

    # ---- evaluation ----
    def eval(self, x: Any, *, params: Optional[Mapping[str, Any]] = None, **kwargs) -> Any:
        values: Dict[str, Any] = {}

        if params is not None:
            for k, v in params.items():
                if isinstance(v, ParamView):
                    values[k] = v.value
                else:
                    # If someone passes a dict-like with ["value"], allow it.
                    try:
                        if hasattr(v, "__getitem__"):
                            values[k] = v["value"]  # type: ignore[index]
                        else:
                            values[k] = v
                    except Exception:
                        values[k] = v

        values.update(kwargs)

        # Fill fixed values if absent
        for spec in self.params:
            if spec.fixed and spec.name not in values:
                values[spec.name] = spec.fixed_value

        missing = [n for n in self.param_names if n not in values]
        if missing:
            raise TypeError(f"Missing parameter values for: {missing}")

        args = [x] + [values[n] for n in self.param_names]
        return self.func(*args)

    # ---- builders (pure; return new model) ----
    def fix(self, **fixed: float) -> "Model":
        m = {p.name: p for p in self.params}
        for k, v in fixed.items():
            if k not in m:
                raise KeyError(k)
            m[k] = replace(m[k], fixed=True, fixed_value=float(v))
        return replace(self, params=tuple(m[n] for n in self.param_names))

    def bound(self, **bounds: Tuple[Optional[float], Optional[float]]) -> "Model":
        m = {p.name: p for p in self.params}
        for k, b in bounds.items():
            if k not in m:
                raise KeyError(k)
            lo, hi = b
            m[k] = replace(m[k], bounds=(lo, hi))
        return replace(self, params=tuple(m[n] for n in self.param_names))

    def guess(self, **guesses: float) -> "Model":
        m = {p.name: p for p in self.params}
        for k, g in guesses.items():
            if k not in m:
                raise KeyError(k)
            m[k] = replace(m[k], guess=float(g))
        return replace(self, params=tuple(m[n] for n in self.param_names))

    def autoguess(self, *names: str) -> "Model":
        for n in names:
            if n not in self.param_names:
                raise KeyError(n)
        merged = tuple(dict.fromkeys(self.autoguess_names + tuple(names)).keys())
        return replace(self, autoguess_names=merged)

    def prior(self, **priors: Tuple[str, Any]) -> "Model":
        m = {p.name: p for p in self.params}
        for k, p in priors.items():
            if k not in m:
                raise KeyError(k)
            if not isinstance(p, tuple) or len(p) < 1:
                raise TypeError("prior must be like ('normal', 0, 1) etc.")
            kind = str(p[0])
            args = tuple(p[1:])
            m[k] = replace(m[k], prior=(kind, args))
        return replace(self, params=tuple(m[n] for n in self.param_names))

    def derive(self, name: str, func: Callable[[Mapping[str, float]], float], *, doc: str = "") -> "Model":
        if name in self.param_names:
            raise ValueError(f"Derived name {name!r} conflicts with an existing parameter.")
        return replace(self, derived=self.derived + (DerivedSpec(name=name, func=func, doc=doc),))

    # ---- guesser registration (side-effect, v1 ergonomic) ----
    def guesser(self, fn: Optional[Guesser] = None):
        """Decorator to register a custom guesser.

        NOTE: This mutates `self` by appending the guesser, and returns the function.
        This supports the ergonomic pattern:

            @model.guesser
            def g(x, y, gs): ...

        Builder methods remain pure (return new models).
        """
        def decorator(f: Guesser) -> Guesser:
            self.guessers = self.guessers + (f,)
            return f

        return decorator(fn) if fn is not None else decorator

    # ---- fitting ----
    def fit(
        self,
        *,
        x: Any,
        y: Any,
        backend: Literal["scipy.curve_fit", "scipy.minimize", "ultranest"] = "scipy.curve_fit",
        data_format: Optional[str] = None,
        parallel: Optional[Literal[None, "auto"]] = None,
        skip: bool = False,
        return_run: bool = False,
        backend_options: Optional[Dict[str, Any]] = None,
        rng: Optional[np.random.Generator] = None,
    ) -> Union[Results, Run]:
        if rng is None:
            rng = np.random.default_rng()
        backend_options = backend_options or {}

        # v1: only Gaussian inference (data_format None or 'normal')
        if data_format not in (None, "normal"):
            raise NotImplementedError("v1 MVP supports only Gaussian default data inference.")

        datasets: List[Dict[str, Any]] = []
        batch_shape: Tuple[int, ...] = ()

        if is_ragged_batch(x, y):
            for xi, yi in zip(x, y):
                yobs, sigma = _infer_gaussian_payload(yi)
                datasets.append({"x": xi, "y": yobs, "sigma": sigma})
            batch_shape = (len(datasets),)
        else:
            yobs, sigma = _infer_gaussian_payload(y)
            yobs = np.asarray(yobs)
            if yobs.ndim == 1:
                datasets.append({"x": x, "y": yobs, "sigma": sigma})
                batch_shape = ()
            else:
                yflat, batch_shape = flatten_batch(yobs)
                # broadcast sigma if needed
                if sigma is None:
                    sflat = [None] * yflat.shape[0]
                else:
                    sarr = np.asarray(sigma)
                    if sarr.shape == ():
                        sflat = [float(sarr)] * yflat.shape[0]
                    else:
                        sb = np.broadcast_to(sarr, yobs.shape)
                        sb_flat, _ = flatten_batch(sb)
                        sflat = [sb_flat[i] for i in range(sb_flat.shape[0])]
                for i in range(yflat.shape[0]):
                    datasets.append({"x": x, "y": yflat[i], "sigma": sflat[i]})

        free_names, fixed_map = _free_and_fixed(self.params)

        # allocate storage (flattened batch)
        B = len(datasets)
        values = {n: np.empty((B,), dtype=float) for n in self.param_names}
        errors = {n: np.full((B,), np.nan, dtype=float) for n in self.param_names}
        seed_values = {n: np.empty((B,), dtype=float) for n in self.param_names}
        covs: List[Optional[np.ndarray]] = []

        meta: Dict[str, Any] = {
            "mode": "seed" if skip else "fit",
            "free_param_names": list(free_names),
            "success": [],
            "message": [],
        }

        for i, ds in enumerate(datasets):
            xi = ds["x"]
            yi = np.asarray(ds["y"])
            si = ds["sigma"]
            si_arr = None if si is None else np.asarray(si, dtype=float)

            p0_map = _initial_guess(self, xi, yi, free_names, rng=rng)
            p0 = np.array([float(p0_map[n]) for n in free_names], dtype=float)
            bounds = _bounds_for_free(self.params, free_names)

            # Record the seed params actually used for this dataset
            for j, n in enumerate(free_names):
                seed_values[n][i] = p0[j]
            for n, fv in fixed_map.items():
                seed_values[n][i] = float(fv)

            if skip:
                meta["success"].append(True)
                meta["message"].append("skipped (seed only)")
                for j, n in enumerate(free_names):
                    values[n][i] = p0[j]
                for n, fv in fixed_map.items():
                    values[n][i] = float(fv)
                covs.append(None)
                continue

            if backend != "scipy.curve_fit":
                raise NotImplementedError("v1 MVP implements only backend='scipy.curve_fit'.")

            f_wrapped = _wrap_free_params(self, fixed_map, free_names)
            r = fit_curve_fit(
                f_wrapped, xi, yi,
                sigma=si_arr, p0=p0, bounds=bounds,
                maxfev=backend_options.get("maxfev"),
            )
            meta["success"].append(r.success)
            meta["message"].append(r.message)

            # store free values
            for j, n in enumerate(free_names):
                values[n][i] = r.popt[j]
            # fixed values
            for n, fv in fixed_map.items():
                values[n][i] = float(fv)

            if r.pcov is not None:
                pcov = np.asarray(r.pcov, dtype=float)
                covs.append(pcov)
                perr = np.sqrt(np.clip(np.diag(pcov), 0.0, np.inf))
                for j, n in enumerate(free_names):
                    errors[n][i] = perr[j]
            else:
                covs.append(None)

        have_any_cov = any(c is not None for c in covs)

        # Build param views + cov
        if batch_shape == ():
            items: Dict[str, ParamView] = {}
            seed_items: Dict[str, ParamView] = {}
            for n in self.param_names:
                spec = _spec_by_name(self.params, n)
                v = float(values[n][0])
                e = float(errors[n][0])
                sv = float(seed_values[n][0])
                items[n] = ParamView(
                    name=n,
                    value=v,
                    error=None if (spec.fixed or not have_any_cov) else e,
                    fixed=spec.fixed,
                    bounds=spec.bounds,
                    derived=False,
                )
                seed_items[n] = ParamView(
                    name=n,
                    value=sv,
                    error=None,
                    fixed=spec.fixed,
                    bounds=spec.bounds,
                    derived=False,
                )
            cov = covs[0] if covs and covs[0] is not None else None
            results = Results(batch_shape=(), params=ParamsView(items), seed=ParamsView(seed_items), cov=cov, backend=backend, meta=meta)
        else:
            items = {}
            seed_items = {}
            for n in self.param_names:
                spec = _spec_by_name(self.params, n)
                v = unflatten_batch(values[n], batch_shape)
                e = unflatten_batch(errors[n], batch_shape)
                sv = unflatten_batch(seed_values[n], batch_shape)
                items[n] = ParamView(
                    name=n,
                    value=v,
                    error=None if (spec.fixed or not have_any_cov) else e,
                    fixed=spec.fixed,
                    bounds=spec.bounds,
                    derived=False,
                )
                seed_items[n] = ParamView(
                    name=n,
                    value=sv,
                    error=None,
                    fixed=spec.fixed,
                    bounds=spec.bounds,
                    derived=False,
                )

            if all(c is not None for c in covs):
                cov = np.stack([c for c in covs], axis=0)
                cov = unflatten_batch(cov, batch_shape)
            else:
                cov = None
            results = Results(batch_shape=batch_shape, params=ParamsView(items), seed=ParamsView(seed_items), cov=cov, backend=backend, meta=meta)

        # Post-fit derived params (v1): depend only on fitted params
        if self.derived:
            if results.batch_shape == ():
                base = {n: float(results.params[n].value) for n in self.param_names}
                extra = {}
                for d in self.derived:
                    dv = float(d.func(base))
                    extra[d.name] = ParamView(name=d.name, value=dv, error=None, fixed=True, derived=True)
                results = replace(results, params=ParamsView({**dict(results.params.items()), **extra}))
            else:
                # flatten again
                batch_size = prod(results.batch_shape)
                flat_vals = {n: np.asarray(results.params[n].value).reshape((batch_size,)) for n in self.param_names}
                extra_items = {}
                for d in self.derived:
                    out = np.empty((batch_size,), dtype=float)
                    for i in range(batch_size):
                        base = {n: float(flat_vals[n][i]) for n in self.param_names}
                        out[i] = float(d.func(base))
                    extra_items[d.name] = ParamView(
                        name=d.name,
                        value=unflatten_batch(out, results.batch_shape),
                        error=None,
                        fixed=True,
                        derived=True,
                    )
                results = replace(results, params=ParamsView({**dict(results.params.items()), **extra_items}))

        run = Run(
            model=self,
            results=results,
            backend=backend,
            data_format=(data_format or "normal"),
            meta=meta,
            data={"x": x, "y": y},
        )

        return run if return_run else results


def _spec_by_name(params: Tuple[ParameterSpec, ...], name: str) -> ParameterSpec:
    for p in params:
        if p.name == name:
            return p
    raise KeyError(name)


def _free_and_fixed(params: Tuple[ParameterSpec, ...]) -> Tuple[List[str], Dict[str, float]]:
    free: List[str] = []
    fixed: Dict[str, float] = {}
    for p in params:
        if p.fixed:
            if p.fixed_value is None:
                raise ValueError(f"Parameter {p.name} is fixed but has no fixed_value.")
            fixed[p.name] = float(p.fixed_value)
        else:
            free.append(p.name)
    return free, fixed


def _bounds_for_free(params: Tuple[ParameterSpec, ...], free_names: List[str]) -> Tuple[np.ndarray, np.ndarray]:
    pmap = {p.name: p for p in params}
    lo: List[float] = []
    hi: List[float] = []
    for n in free_names:
        b = pmap[n].bounds
        if b is None:
            lo.append(-np.inf)
            hi.append(np.inf)
        else:
            lo.append(-np.inf if b[0] is None else float(b[0]))
            hi.append(np.inf if b[1] is None else float(b[1]))
    return (np.array(lo, dtype=float), np.array(hi, dtype=float))


def _wrap_free_params(model: Model, fixed_map: Dict[str, float], free_names: List[str]):
    def f(x, *theta_free):
        kwargs = dict(fixed_map)
        for j, n in enumerate(free_names):
            kwargs[n] = theta_free[j]
        return model.eval(x, **kwargs)
    return f


def _infer_gaussian_payload(y: Any):
    # v1 default inference:
    # y -> unweighted
    # (y, yerr) -> symmetric absolute errors
    # (y, yerr_low, yerr_high) -> asymmetric; approximate to mean sigma for curve_fit
    if isinstance(y, (tuple, list)) and len(y) == 2:
        yobs, yerr = y
        return np.asarray(yobs), yerr
    if isinstance(y, (tuple, list)) and len(y) == 3:
        yobs, ylo, yhi = y
        sigma = 0.5 * (np.asarray(ylo) + np.asarray(yhi))
        return np.asarray(yobs), sigma
    return np.asarray(y), None


def _initial_guess(model: Model, x: Any, y: np.ndarray, free_names: List[str], rng: np.random.Generator) -> Dict[str, float]:
    pmap = {p.name: p for p in model.params}
    g: Dict[str, float] = {}

    # manual guesses
    for n in free_names:
        if pmap[n].guess is not None:
            g[n] = float(pmap[n].guess)

    # built-in heuristics for autoguess names (only if unset)
    if model.autoguess_names:
        g2 = _builtin_autoguess(x, y, model.autoguess_names)
        for n, v in g2.items():
            if n in free_names and n not in g:
                g[n] = float(v)

    # user guessers
    if model.guessers:
        gs = GuessState()
        for fn in model.guessers:
            fn(x, y, gs)
        for n, v in gs.to_dict().items():
            if n in free_names and n not in g:
                g[n] = float(v)

    # final fill
    for n in free_names:
        if n not in g:
            g[n] = 0.0
    return g


def _builtin_autoguess(x: Any, y: np.ndarray, names: Sequence[str]) -> Dict[str, float]:
    out: Dict[str, float] = {}
    y = np.asarray(y)

    # If x is a container, use first entry for slope-type heuristics.
    x0 = x[0] if isinstance(x, (tuple, list)) and len(x) > 0 else x
    x0 = np.asarray(x0)

    for n in names:
        if n in ("b", "c", "offset", "intercept"):
            out[n] = float(np.median(y))
        elif n in ("m", "slope"):
            if x0.size >= 2:
                out[n] = float((y[-1] - y[0]) / (x0[-1] - x0[0] + 1e-12))
            else:
                out[n] = 0.0
        elif n in ("amplitude", "amp", "A"):
            out[n] = float(0.5 * (np.nanmax(y) - np.nanmin(y)))
        elif n in ("mu", "mean", "center"):
            out[n] = float(np.nanmean(x0))
        elif n in ("sigma", "width"):
            out[n] = float(0.1 * (np.nanmax(x0) - np.nanmin(x0) + 1e-12))
        else:
            # unknown name: no-op
            pass

    # Special case: if both m and b requested, attempt polyfit
    if (("m" in names) or ("slope" in names)) and (("b" in names) or ("intercept" in names)):
        if x0.ndim == 1 and x0.size == y.size:
            try:
                m, b = np.polyfit(x0, y, deg=1)
                out.setdefault("m", float(m))
                out.setdefault("b", float(b))
                out.setdefault("slope", float(m))
                out.setdefault("intercept", float(b))
            except Exception:
                pass

    return out


# === src/sensible_fitting/models.py ===

from __future__ import annotations

import numpy as np

from .model import Model


def straight_line(*, name: str = "straight line") -> Model:
    def line(x, m, b):
        return m * x + b
    return Model.from_function(line, name=name).autoguess("m", "b")


def sinusoid(*, name: str = "sinusoid") -> Model:
    def s(x, amplitude, offset, frequency, phase):
        return offset + amplitude * np.sin(2 * np.pi * frequency * x + phase)
    return Model.from_function(s, name=name).autoguess("amplitude", "offset")


# === src/sensible_fitting/params.py ===

from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Dict, Mapping, Optional, Tuple

import numpy as np


@dataclass(frozen=True)
class ParameterSpec:
    name: str
    fixed: bool = False
    fixed_value: Optional[float] = None
    bounds: Optional[Tuple[Optional[float], Optional[float]]] = None
    guess: Optional[float] = None
    # Stored for Bayesian backends (ignored by curve_fit in v1)
    prior: Optional[Tuple[str, Tuple[Any, ...]]] = None
    meta: Dict[str, Any] = None


@dataclass(frozen=True)
class DerivedSpec:
    """Post-fit derived parameter (v1).

    v1 restriction:
    - computed only AFTER fitting
    - depends only on fitted params, not on other derived params
    """
    name: str
    func: Any  # Callable[[Mapping[str, float]], float]
    doc: str = ""
    meta: Dict[str, Any] = None


@dataclass(frozen=True)
class ParamView:
    """A single parameter view."""
    name: str
    value: Any
    error: Any = None
    fixed: Any = False
    bounds: Optional[Tuple[Optional[float], Optional[float]]] = None
    derived: bool = False
    meta: Dict[str, Any] = None

    def __getitem__(self, key: str) -> Any:
        if key == "value":
            return self.value
        if key in ("error", "stderr"):
            return self.error
        if key == "fixed":
            return self.fixed
        if key == "bounds":
            return self.bounds
        if key == "derived":
            return self.derived
        raise KeyError(key)


class ParamsView(Mapping[str, ParamView]):
    """Mapping name -> ParamView."""

    def __init__(self, items: Mapping[str, ParamView]):
        self._items = dict(items)

    def __getitem__(self, key: str) -> ParamView:
        return self._items[key]

    def __iter__(self):
        return iter(self._items)

    def __len__(self):
        return len(self._items)

    def items(self):
        return self._items.items()

    def as_dict(self) -> Dict[str, Any]:
        """Return name->value (extracting .value)."""
        return {k: v.value for k, v in self._items.items()}


class GuessState:
    """Mutable guess state passed to guessers.

    Supports:
        g.amplitude = 1.0
        g.is_unset("amplitude")
    """

    def __init__(self):
        object.__setattr__(self, "_d", {})

    def __getattr__(self, name: str) -> Any:
        d = object.__getattribute__(self, "_d")
        if name in d:
            return d[name]
        raise AttributeError(name)

    def __setattr__(self, name: str, value: Any) -> None:
        if name == "_d":
            object.__setattr__(self, name, value)
            return
        d = object.__getattribute__(self, "_d")
        d[name] = value

    def is_unset(self, name: str) -> bool:
        d = object.__getattribute__(self, "_d")
        return name not in d

    def to_dict(self) -> Dict[str, Any]:
        return dict(object.__getattribute__(self, "_d"))


# === src/sensible_fitting/run.py ===

from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Dict, Literal, Optional, Tuple

import numpy as np

from .params import ParamView, ParamsView
from .util import level_to_conf_int, prod, sample_mvn


@dataclass(frozen=True)
class Band:
    low: np.ndarray
    high: np.ndarray
    median: Optional[np.ndarray] = None
    meta: Dict[str, Any] = None


@dataclass(frozen=True)
class Results:
    batch_shape: Tuple[int, ...]
    params: ParamsView
    seed: Optional[ParamsView] = None
    cov: Optional[np.ndarray] = None
    backend: str = ""
    meta: Dict[str, Any] = None

    def __getitem__(self, idx) -> "Results":
        if self.batch_shape == ():
            raise IndexError("Scalar Results cannot be indexed; already squeezed.")

        def _slice(v):
            if v is None:
                return None
            a = np.asarray(v)
            if a.shape == ():
                return v
            return a[idx]

        new_items: Dict[str, ParamView] = {}
        for name, pv in self.params.items():
            new_items[name] = ParamView(
                name=name,
                value=_slice(pv.value),
                error=_slice(pv.error),
                fixed=_slice(pv.fixed) if isinstance(pv.fixed, np.ndarray) else pv.fixed,
                bounds=pv.bounds,
                derived=pv.derived,
                meta=pv.meta,
            )

        new_seed = None
        if self.seed is not None:
            seed_items: Dict[str, ParamView] = {}
            for name, pv in self.seed.items():
                seed_items[name] = ParamView(
                    name=name,
                    value=_slice(pv.value),
                    error=_slice(pv.error),
                    fixed=_slice(pv.fixed) if isinstance(pv.fixed, np.ndarray) else pv.fixed,
                    bounds=pv.bounds,
                    derived=pv.derived,
                    meta=pv.meta,
                )
            new_seed = ParamsView(seed_items)


        cov = self.cov
        if cov is not None and np.asarray(cov).ndim >= 3:
            cov = np.asarray(cov)[idx]

        new_batch_shape = ()
        for pv in new_items.values():
            a = np.asarray(pv.value)
            if a.shape != ():
                new_batch_shape = a.shape
                break

        return Results(
            batch_shape=tuple(new_batch_shape),
            params=ParamsView(new_items),
            seed=new_seed,
            cov=cov,
            backend=self.backend,
            meta=self.meta,
        )

    def summary(self, digits: int = 4) -> str:
        meta = self.meta or {}
        lines = [f"Results(backend={self.backend!r}, batch_shape={self.batch_shape})"]

        if self.batch_shape == ():
            for name, pv in self.params.items():
                v = pv.value
                e = pv.error
                tag = " (derived)" if pv.derived else ""
                if e is None:
                    lines.append(f"  {name:>12s}: {float(v):.{digits}g}{tag}")
                else:
                    lines.append(f"  {name:>12s}: {float(v):.{digits}g} ± {float(e):.{digits}g}{tag}")
            return "\n".join(lines)

        batch_size = prod(self.batch_shape)
        show = min(batch_size, 10)
        names = list(self.params.keys())

        header = "idx " + " ".join([f"{n:>14s}" for n in names])
        lines.append(header)
        lines.append("-" * len(header))

        for i in range(show):
            row = [f"{i:>3d}"]
            for n in names:
                pv = self.params[n]
                v = np.asarray(pv.value).reshape((batch_size,))[i]
                e = pv.error
                if e is None:
                    row.append(f"{float(v):>14.{digits}g}")
                else:
                    eflat = np.asarray(e).reshape((batch_size,))[i]
                    row.append(f"{float(v):>7.{digits}g}±{float(eflat):<6.{digits}g}")
            lines.append(" ".join(row))

        if batch_size > show:
            lines.append(f"... ({batch_size-show} more)")
        return "\n".join(lines)


@dataclass(frozen=True)
class Run:
    model: Any  # Model
    results: Results
    backend: str
    data_format: str
    meta: Dict[str, Any] = None
    data: Dict[str, Any] = None

    def squeeze(self) -> "Run":
        if self.results.batch_shape == ():
            return self
        batch_size = prod(self.results.batch_shape)
        if batch_size != 1:
            raise ValueError(f"run.squeeze() requires exactly one fit; got batch_size={batch_size}. Slice first.")
        idx = tuple(0 for _ in self.results.batch_shape)
        return self[idx]

    def __getitem__(self, idx) -> "Run":
        sub_results = self.results[idx]

        sub_data = None
        if self.data is not None:
            sub_data = {}
            bs = self.results.batch_shape  # batch shape *before* slicing

            for k, v in self.data.items():
                # Ragged batch stores list-of-datasets; index directly.
                if isinstance(v, list):
                    sub_data[k] = v[idx]

                # Structured payload tuples like (y, sigma) or (y, lo, hi):
                # slice any numpy array that carries the batch dimension.
                elif isinstance(v, tuple):
                    parts = []
                    for part in v:
                        if isinstance(part, np.ndarray) and bs != () and part.shape[: len(bs)] == bs:
                            parts.append(part[idx])
                        else:
                            parts.append(part)
                    sub_data[k] = tuple(parts)

                else:
                    sub_data[k] = v

        return Run(
            model=self.model,
            results=sub_results,
            backend=self.backend,
            data_format=self.data_format,
            meta=self.meta,
            data=sub_data,
        )


    def band(
        self,
        x: Any,
        *,
        nsamples: int = 400,
        level: Optional[float] = None,
        conf_int: Optional[Tuple[float, float]] = None,
        method: Literal["auto", "posterior", "covariance"] = "auto",
        rng: Optional[np.random.Generator] = None,
    ) -> Band:
        if self.results.batch_shape != ():
            raise ValueError("run.band() requires a scalar run. Slice first (e.g., run[i].band(...)).")

        if rng is None:
            rng = np.random.default_rng()

        if level is None and conf_int is None:
            level = 2.0
        if level is not None and conf_int is not None:
            raise ValueError("Provide only one of level= or conf_int=.")

        if conf_int is None:
            qlo, qhi = level_to_conf_int(float(level))
        else:
            qlo, qhi = conf_int

        # v1: covariance-only (posterior reserved)
        if method not in ("auto", "covariance"):
            raise NotImplementedError("v1: posterior-based band() is reserved.")

        cov = self.results.cov
        if cov is None:
            raise ValueError("No covariance available for band().")

        meta = self.results.meta or {}
        free_names = meta.get("free_param_names")
        if not free_names:
            raise ValueError("Results.meta['free_param_names'] missing; cannot compute band().")

        mean = np.array([float(self.results.params[n].value) for n in free_names], dtype=float)
        cov = np.asarray(cov, dtype=float)

        theta = sample_mvn(mean, cov, int(nsamples), rng)  # (S,P)

        preds = []
        for s in range(theta.shape[0]):
            p = {name: theta[s, j] for j, name in enumerate(free_names)}
            preds.append(np.asarray(self.model.eval(x, **p)))
        preds = np.stack(preds, axis=0)

        lo = np.quantile(preds, qlo, axis=0)
        hi = np.quantile(preds, qhi, axis=0)
        med = np.quantile(preds, 0.5, axis=0)

        return Band(low=lo, high=hi, median=med, meta={"method": "covariance", "q": (qlo, qhi)})


# === src/sensible_fitting/util.py ===

from __future__ import annotations

import inspect
import math
from typing import Any, Callable, Tuple

import numpy as np


def normal_cdf(z: float) -> float:
    """Standard Normal CDF Φ(z)."""
    return 0.5 * (1.0 + math.erf(z / math.sqrt(2.0)))


def level_to_conf_int(level: float) -> Tuple[float, float]:
    """Central interval for a Normal-equivalent ±level sigma."""
    lo = normal_cdf(-float(level))
    hi = normal_cdf(+float(level))
    return (lo, hi)


def infer_param_names(func: Callable[..., Any]) -> Tuple[str, ...]:
    """Infer parameter names from a function signature.

    Conventions:
    - first arg is independent variable container (x)
    - remaining positional/keyword parameters are fit parameters

    v1 restriction:
    - no *args/**kwargs in model functions
    """
    sig = inspect.signature(func)
    params = list(sig.parameters.values())

    if len(params) < 2:
        raise TypeError("Model function must have at least (x, p1, ...).")

    bad_kinds = {inspect.Parameter.VAR_POSITIONAL, inspect.Parameter.VAR_KEYWORD}
    for p in params:
        if p.kind in bad_kinds:
            raise TypeError("v1: *args/**kwargs are not supported in model functions.")

    names = [p.name for p in params[1:]]
    if len(set(names)) != len(names):
        raise TypeError("Duplicate parameter names in function signature.")
    return tuple(names)


def prod(shape: Tuple[int, ...]) -> int:
    n = 1
    for s in shape:
        n *= int(s)
    return int(n)


def flatten_batch(arr: np.ndarray) -> Tuple[np.ndarray, Tuple[int, ...]]:
    """Flatten batch dimensions of an array shaped batch_shape + (N,).

    Returns
    -------
    arr_flat : ndarray, shape (B, N) where B=prod(batch_shape)
    batch_shape : tuple
        Empty tuple means scalar/single dataset.
    """
    arr = np.asarray(arr)
    if arr.ndim == 1:
        return arr[None, :], ()
    batch_shape = tuple(arr.shape[:-1])
    B = prod(batch_shape)
    N = arr.shape[-1]
    return arr.reshape(B, N), batch_shape


def unflatten_batch(values: np.ndarray, batch_shape: Tuple[int, ...]) -> np.ndarray:
    """Unflatten arrays with leading dimension B back to batch_shape."""
    values = np.asarray(values)
    if batch_shape == ():
        return values.reshape(())
    return values.reshape(batch_shape + values.shape[1:])


def _jittered_cholesky(cov: np.ndarray, max_tries: int = 6) -> np.ndarray:
    cov = np.asarray(cov, dtype=float)
    cov = 0.5 * (cov + cov.T)
    diag = np.diag(cov)
    scale = float(np.max(diag)) if diag.size else 1.0
    scale = 1.0 if not np.isfinite(scale) or scale <= 0 else scale

    jitter = 0.0
    for i in range(max_tries):
        try:
            return np.linalg.cholesky(cov + jitter * np.eye(cov.shape[0]))
        except np.linalg.LinAlgError:
            jitter = (10.0 ** (-(max_tries - i))) * 1e-6 * scale + (jitter * 10.0 if jitter else 0.0)

    w, v = np.linalg.eigh(cov)
    w = np.clip(w, 0.0, None)
    return v @ np.diag(np.sqrt(w))


def sample_mvn(mean: np.ndarray, cov: np.ndarray, nsamples: int, rng: np.random.Generator) -> np.ndarray:
    """Sample from MVN(mean, cov) robustly. Returns shape (nsamples, P)."""
    mean = np.asarray(mean, dtype=float)
    cov = np.asarray(cov, dtype=float)
    L = _jittered_cholesky(cov)
    z = rng.normal(size=(nsamples, mean.shape[0]))
    return mean[None, :] + z @ L.T


def is_sequence(x: Any) -> bool:
    return isinstance(x, (list, tuple))


def is_ragged_batch(x: Any, y: Any) -> bool:
    """Heuristic: x and y are sequences of equal length => ragged batch."""
    return is_sequence(x) and is_sequence(y) and len(x) == len(y)


def safe_float(x: Any) -> float:
    """Convert numpy scalar / 0-d array to python float."""
    if isinstance(x, np.ndarray) and x.shape == ():
        return float(x.item())
    return float(x)
